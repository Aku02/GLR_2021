{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiovascular-gothic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:28.631909Z",
     "iopub.status.busy": "2021-09-29T19:13:28.629938Z",
     "iopub.status.idle": "2021-09-29T19:13:32.286695Z",
     "shell.execute_reply": "2021-09-29T19:13:32.285984Z",
     "shell.execute_reply.started": "2021-09-29T18:39:24.578142Z"
    },
    "papermill": {
     "duration": 3.718727,
     "end_time": "2021-09-29T19:13:32.286863",
     "exception": false,
     "start_time": "2021-09-29T19:13:28.568136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import sys\n",
    "import importlib\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torch.cuda.amp import autocast\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-venture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:32.401131Z",
     "iopub.status.busy": "2021-09-29T19:13:32.400387Z",
     "iopub.status.idle": "2021-09-29T19:13:32.405939Z",
     "shell.execute_reply": "2021-09-29T19:13:32.405375Z",
     "shell.execute_reply.started": "2021-09-29T18:39:27.612299Z"
    },
    "papermill": {
     "duration": 0.063986,
     "end_time": "2021-09-29T19:13:32.406105",
     "exception": false,
     "start_time": "2021-09-29T19:13:32.342119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FAST_COMMIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polar-islam",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:32.522015Z",
     "iopub.status.busy": "2021-09-29T19:13:32.521213Z",
     "iopub.status.idle": "2021-09-29T19:13:38.651708Z",
     "shell.execute_reply": "2021-09-29T19:13:38.652373Z",
     "shell.execute_reply.started": "2021-09-29T18:39:27.622172Z"
    },
    "papermill": {
     "duration": 6.191037,
     "end_time": "2021-09-29T19:13:38.652559",
     "exception": false,
     "start_time": "2021-09-29T19:13:32.461522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/landmarks-pip-wheels-v1/timm-0.4.13.zip\r\n",
      "Building wheels for collected packages: timm\r\n",
      "  Building wheel for timm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for timm: filename=timm-0.4.13-py3-none-any.whl size=397531 sha256=c4afe768983f65a126546abb46a64eb8ad7587bd332d73475e285233507b11d9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/e3/72/90220049ef45f95675a9e0e6e74440a61876ccde62bd8c3a2c\r\n",
      "Successfully built timm\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/landmarks-pip-wheels-v1/timm-0.4.13.zip --no-index --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "third-little",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:38.779324Z",
     "iopub.status.busy": "2021-09-29T19:13:38.778274Z",
     "iopub.status.idle": "2021-09-29T19:13:39.540639Z",
     "shell.execute_reply": "2021-09-29T19:13:39.540100Z",
     "shell.execute_reply.started": "2021-09-29T18:39:33.004338Z"
    },
    "papermill": {
     "duration": 0.829601,
     "end_time": "2021-09-29T19:13:39.540802",
     "exception": false,
     "start_time": "2021-09-29T19:13:38.711201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/landmark-retrieval-2021-codebase/configs.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/landmark-retrieval-2021-codebase/configs.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-stream",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:39.676752Z",
     "iopub.status.busy": "2021-09-29T19:13:39.671423Z",
     "iopub.status.idle": "2021-09-29T19:13:46.035279Z",
     "shell.execute_reply": "2021-09-29T19:13:46.035954Z",
     "shell.execute_reply.started": "2021-09-29T18:39:33.705893Z"
    },
    "papermill": {
     "duration": 6.436744,
     "end_time": "2021-09-29T19:13:46.036131",
     "exception": false,
     "start_time": "2021-09-29T19:13:39.599387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# move codebase\n",
    "!mkdir configs\n",
    "!mkdir data\n",
    "!mkdir models\n",
    "\n",
    "!cp ../input/landmark-retrieval-2021-codebase/* ./\n",
    "!tar -xvf ./configs.tar -C ./configs >> /dev/null\n",
    "!tar -xvf ./data.tar -C ./data >> /dev/null\n",
    "!tar -xvf ./models.tar -C ./models >> /dev/null\n",
    "!rm ./*.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brave-climate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:46.166305Z",
     "iopub.status.busy": "2021-09-29T19:13:46.165124Z",
     "iopub.status.idle": "2021-09-29T19:13:46.169075Z",
     "shell.execute_reply": "2021-09-29T19:13:46.168487Z",
     "shell.execute_reply.started": "2021-09-29T18:39:39.409896Z"
    },
    "papermill": {
     "duration": 0.069132,
     "end_time": "2021-09-29T19:13:46.169192",
     "exception": false,
     "start_time": "2021-09-29T19:13:46.100060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('./configs')\n",
    "sys.path.append('./data')\n",
    "sys.path.append('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "senior-glasgow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:46.305391Z",
     "iopub.status.busy": "2021-09-29T19:13:46.304299Z",
     "iopub.status.idle": "2021-09-29T19:13:46.308706Z",
     "shell.execute_reply": "2021-09-29T19:13:46.308173Z",
     "shell.execute_reply.started": "2021-09-29T18:40:14.198096Z"
    },
    "papermill": {
     "duration": 0.076096,
     "end_time": "2021-09-29T19:13:46.308889",
     "exception": false,
     "start_time": "2021-09-29T19:13:46.232793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob \n",
    "\n",
    "def get_file_names(path):\n",
    "    file_names = glob(os.path.join(path, *['*'] * 3, '*.jpg'))\n",
    "    return file_names\n",
    "\n",
    "def convert_to_image_ids(fnames):\n",
    "    image_ids = []\n",
    "    for fname in fnames:\n",
    "        image_id = os.path.splitext(os.path.basename(fname))[0]\n",
    "        image_ids.append(image_id)\n",
    "    return image_ids\n",
    "\n",
    "def get_image_ids(path):\n",
    "    file_names = get_file_names(path)\n",
    "    image_ids = convert_to_image_ids(file_names)\n",
    "    return image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-moore",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:13:46.443079Z",
     "iopub.status.busy": "2021-09-29T19:13:46.442276Z",
     "iopub.status.idle": "2021-09-29T19:14:07.120314Z",
     "shell.execute_reply": "2021-09-29T19:14:07.118760Z",
     "shell.execute_reply.started": "2021-09-29T18:51:32.676316Z"
    },
    "papermill": {
     "duration": 20.748708,
     "end_time": "2021-09-29T19:14:07.120529",
     "exception": false,
     "start_time": "2021-09-29T19:13:46.371821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMP_FOLDER = '../input/landmark-retrieval-2021/'\n",
    "\n",
    "data_path = '../input/landmark-retrieval-2021'\n",
    "index_path = os.path.join(data_path, 'index')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "\n",
    "index_ids = get_image_ids(index_path)\n",
    "test_ids = get_image_ids(test_path)\n",
    "# train_ids = get_image_ids(train_path)\n",
    "train_csv = pd.read_csv(\"../input/landmark-retrieval-2021/train.csv\")\n",
    "train_ids = train_csv[\"id\"].values\n",
    "\n",
    "N_CORES = mp.cpu_count()\n",
    "PUBLIC_RUN = len(test_ids) == 1129\n",
    "RAM_CHECK = False\n",
    "TOPK = 1000\n",
    "eps = 1e-8\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blessed-press",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:07.249759Z",
     "iopub.status.busy": "2021-09-29T19:14:07.247846Z",
     "iopub.status.idle": "2021-09-29T19:14:07.251234Z",
     "shell.execute_reply": "2021-09-29T19:14:07.251790Z",
     "shell.execute_reply.started": "2021-09-29T18:51:39.949629Z"
    },
    "papermill": {
     "duration": 0.074233,
     "end_time": "2021-09-29T19:14:07.251966",
     "exception": false,
     "start_time": "2021-09-29T19:14:07.177733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PUBLIC_RUN and FAST_COMMIT:\n",
    "    TOPK = 51\n",
    "    index_df = pd.DataFrame({\"id\": index_ids[:TOPK]})\n",
    "    test = pd.DataFrame({\"id\": test_ids[:TOPK]})\n",
    "    train = pd.DataFrame({\"id\": train_ids[:TOPK]})\n",
    "else:\n",
    "    index_df = pd.DataFrame({\"id\": index_ids})\n",
    "    test = pd.DataFrame({\"id\": test_ids})\n",
    "    train = pd.DataFrame({\"id\": train_ids})\n",
    "\n",
    "index_df[\"landmark_id\"] = -1\n",
    "test[\"landmark_id\"] = -1\n",
    "train[\"landmark_id\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "backed-disclaimer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:07.381116Z",
     "iopub.status.busy": "2021-09-29T19:14:07.374501Z",
     "iopub.status.idle": "2021-09-29T19:14:08.148293Z",
     "shell.execute_reply": "2021-09-29T19:14:08.147680Z",
     "shell.execute_reply.started": "2021-09-29T18:51:41.502049Z"
    },
    "papermill": {
     "duration": 0.837988,
     "end_time": "2021-09-29T19:14:08.148438",
     "exception": false,
     "start_time": "2021-09-29T19:14:07.310450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          16015         730        9937           0        5347       15010\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aboriginal-incident",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:08.281733Z",
     "iopub.status.busy": "2021-09-29T19:14:08.280035Z",
     "iopub.status.idle": "2021-09-29T19:14:25.920935Z",
     "shell.execute_reply": "2021-09-29T19:14:25.921677Z",
     "shell.execute_reply.started": "2021-09-29T18:51:43.386891Z"
    },
    "papermill": {
     "duration": 17.716901,
     "end_time": "2021-09-29T19:14:25.921993",
     "exception": false,
     "start_time": "2021-09-29T19:14:08.205092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/base_ds_v1.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ) * cfg.arcface_m_x + cfg.arcface_m_y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../input/landmark-pp-5c/checkpoint_last_seed337504.pth']\n",
      "../input/landmark-pp-5c/checkpoint_last_seed337504.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "cfg = importlib.import_module('pp_5c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}test/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}test/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(test, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_test_1 = []\n",
    "    logits_top1000_test_1 = []\n",
    "    inds_top1000_test_1 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_test_1 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_test_1 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_test_1 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "        \n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_test_1 = torch.cat(embeddings_image_test_1)\n",
    "    logits_top1000_test_1 = torch.cat(logits_top1000_test_1)\n",
    "    inds_top1000_test_1 = torch.cat(inds_top1000_test_1)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "israeli-engagement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:26.059537Z",
     "iopub.status.busy": "2021-09-29T19:14:26.058334Z",
     "iopub.status.idle": "2021-09-29T19:14:30.062499Z",
     "shell.execute_reply": "2021-09-29T19:14:30.063261Z",
     "shell.execute_reply.started": "2021-09-29T18:52:03.250756Z"
    },
    "papermill": {
     "duration": 4.080377,
     "end_time": "2021-09-29T19:14:30.063525",
     "exception": false,
     "start_time": "2021-09-29T19:14:25.983148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-5c/checkpoint_last_seed337504.pth']\n",
      "../input/landmark-pp-5c/checkpoint_last_seed337504.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/base_ds_v1.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ) * cfg.arcface_m_x + cfg.arcface_m_y\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# index\n",
    "\n",
    "cfg = importlib.import_module('pp_5c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}index/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}index/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(index_df, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_index_1 = []\n",
    "    logits_top1000_index_1 = []\n",
    "    inds_top1000_index_1 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_index_1 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_index_1 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_index_1 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_index_1 = torch.cat(embeddings_image_index_1)\n",
    "    logits_top1000_index_1 = torch.cat(logits_top1000_index_1)\n",
    "    inds_top1000_index_1 = torch.cat(inds_top1000_index_1)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "particular-instruction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:30.295980Z",
     "iopub.status.busy": "2021-09-29T19:14:30.294944Z",
     "iopub.status.idle": "2021-09-29T19:14:34.538993Z",
     "shell.execute_reply": "2021-09-29T19:14:34.537990Z",
     "shell.execute_reply.started": "2021-09-29T18:52:06.799618Z"
    },
    "papermill": {
     "duration": 4.364278,
     "end_time": "2021-09-29T19:14:34.539149",
     "exception": false,
     "start_time": "2021-09-29T19:14:30.174871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-5c/checkpoint_last_seed337504.pth']\n",
      "../input/landmark-pp-5c/checkpoint_last_seed337504.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "cfg = importlib.import_module('pp_5c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}train/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}train/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(train, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_train_1 = []\n",
    "    logits_top1000_train_1 = []\n",
    "    inds_top1000_train_1 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_train_1 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_train_1 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_train_1 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_train_1 = torch.cat(embeddings_image_train_1)\n",
    "    logits_top1000_train_1 = torch.cat(logits_top1000_train_1)\n",
    "    inds_top1000_train_1 = torch.cat(inds_top1000_train_1)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solved-wrapping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:34.692397Z",
     "iopub.status.busy": "2021-09-29T19:14:34.687304Z",
     "iopub.status.idle": "2021-09-29T19:14:52.071587Z",
     "shell.execute_reply": "2021-09-29T19:14:52.070734Z",
     "shell.execute_reply.started": "2021-09-29T18:59:16.838896Z"
    },
    "papermill": {
     "duration": 17.46476,
     "end_time": "2021-09-29T19:14:52.071868",
     "exception": false,
     "start_time": "2021-09-29T19:14:34.607108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth']\n",
      "../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9b_inf600')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}test/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}test/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(test, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9b/checkpoint_*.pth'))[-1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_test_2 = []\n",
    "    logits_top1000_test_2 = []\n",
    "    inds_top1000_test_2 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_test_2 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_test_2 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_test_2 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "        \n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_test_2 = torch.cat(embeddings_image_test_2)\n",
    "    logits_top1000_test_2 = torch.cat(logits_top1000_test_2)\n",
    "    inds_top1000_test_2 = torch.cat(inds_top1000_test_2)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alpine-physics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:52.219477Z",
     "iopub.status.busy": "2021-09-29T19:14:52.215990Z",
     "iopub.status.idle": "2021-09-29T19:14:58.794454Z",
     "shell.execute_reply": "2021-09-29T19:14:58.795222Z",
     "shell.execute_reply.started": "2021-09-29T18:59:38.645321Z"
    },
    "papermill": {
     "duration": 6.656992,
     "end_time": "2021-09-29T19:14:58.795422",
     "exception": false,
     "start_time": "2021-09-29T19:14:52.138430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth']\n",
      "../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9b_inf600')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}index/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}index/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(index_df, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9b/checkpoint_*.pth'))[-1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_index_2 = []\n",
    "    logits_top1000_index_2 = []\n",
    "    inds_top1000_index_2 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_index_2 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_index_2 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_index_2 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_index_2 = torch.cat(embeddings_image_index_2)\n",
    "    logits_top1000_index_2 = torch.cat(logits_top1000_index_2)\n",
    "    inds_top1000_index_2 = torch.cat(inds_top1000_index_2)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "frozen-somewhere",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:14:58.949388Z",
     "iopub.status.busy": "2021-09-29T19:14:58.948187Z",
     "iopub.status.idle": "2021-09-29T19:15:06.253540Z",
     "shell.execute_reply": "2021-09-29T19:15:06.252867Z",
     "shell.execute_reply.started": "2021-09-29T18:59:45.040247Z"
    },
    "papermill": {
     "duration": 7.390477,
     "end_time": "2021-09-29T19:15:06.253698",
     "exception": false,
     "start_time": "2021-09-29T19:14:58.863221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth']\n",
      "../input/landmark-pp-9b/checkpoint_last_seed882650_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9b_inf600')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}train/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}train/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(train, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9b/checkpoint_*.pth'))[-1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_train_2 = []\n",
    "    logits_top1000_train_2 = []\n",
    "    inds_top1000_train_2 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_train_2 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_train_2 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_train_2 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_train_2 = torch.cat(embeddings_image_train_2)\n",
    "    logits_top1000_train_2 = torch.cat(logits_top1000_train_2)\n",
    "    inds_top1000_train_2 = torch.cat(inds_top1000_train_2)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "large-sight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:15:06.414100Z",
     "iopub.status.busy": "2021-09-29T19:15:06.413029Z",
     "iopub.status.idle": "2021-09-29T19:15:23.985335Z",
     "shell.execute_reply": "2021-09-29T19:15:23.986083Z",
     "shell.execute_reply.started": "2021-09-29T18:59:51.227516Z"
    },
    "papermill": {
     "duration": 17.661476,
     "end_time": "2021-09-29T19:15:23.986255",
     "exception": false,
     "start_time": "2021-09-29T19:15:06.324779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}test/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}test/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(test, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_test_3 = []\n",
    "    logits_top1000_test_3 = []\n",
    "    inds_top1000_test_3 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_test_3 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_test_3 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_test_3 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "        \n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_test_3 = torch.cat(embeddings_image_test_3)\n",
    "    logits_top1000_test_3 = torch.cat(logits_top1000_test_3)\n",
    "    inds_top1000_test_3 = torch.cat(inds_top1000_test_3)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "immediate-basketball",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:15:24.145959Z",
     "iopub.status.busy": "2021-09-29T19:15:24.143827Z",
     "iopub.status.idle": "2021-09-29T19:15:30.855296Z",
     "shell.execute_reply": "2021-09-29T19:15:30.854748Z",
     "shell.execute_reply.started": "2021-09-29T19:00:13.421637Z"
    },
    "papermill": {
     "duration": 6.799177,
     "end_time": "2021-09-29T19:15:30.855439",
     "exception": false,
     "start_time": "2021-09-29T19:15:24.056262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}index/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}index/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(index_df, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_index_3 = []\n",
    "    logits_top1000_index_3 = []\n",
    "    inds_top1000_index_3 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_index_3 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_index_3 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_index_3 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_index_3 = torch.cat(embeddings_image_index_3)\n",
    "    logits_top1000_index_3 = torch.cat(logits_top1000_index_3)\n",
    "    inds_top1000_index_3 = torch.cat(inds_top1000_index_3)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "public-headset",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:15:31.020174Z",
     "iopub.status.busy": "2021-09-29T19:15:31.019055Z",
     "iopub.status.idle": "2021-09-29T19:15:37.966850Z",
     "shell.execute_reply": "2021-09-29T19:15:37.967815Z",
     "shell.execute_reply.started": "2021-09-29T19:00:19.916896Z"
    },
    "papermill": {
     "duration": 7.038302,
     "end_time": "2021-09-29T19:15:37.967993",
     "exception": false,
     "start_time": "2021-09-29T19:15:30.929691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147_ep2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}train/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}train/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(train, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_train_3 = []\n",
    "    logits_top1000_train_3 = []\n",
    "    inds_top1000_train_3 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_train_3 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_train_3 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_train_3 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_train_3 = torch.cat(embeddings_image_train_3)\n",
    "    logits_top1000_train_3 = torch.cat(logits_top1000_train_3)\n",
    "    inds_top1000_train_3 = torch.cat(inds_top1000_train_3)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "auburn-adrian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:15:38.144756Z",
     "iopub.status.busy": "2021-09-29T19:15:38.138945Z",
     "iopub.status.idle": "2021-09-29T19:15:57.182853Z",
     "shell.execute_reply": "2021-09-29T19:15:57.183555Z",
     "shell.execute_reply.started": "2021-09-29T19:00:26.208318Z"
    },
    "papermill": {
     "duration": 19.138401,
     "end_time": "2021-09-29T19:15:57.183869",
     "exception": false,
     "start_time": "2021-09-29T19:15:38.045468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (800, 800)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c_inf800_3')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}test/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}test/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(test, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_test_4 = []\n",
    "    logits_top1000_test_4 = []\n",
    "    inds_top1000_test_4 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_test_4 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_test_4 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_test_4 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "        \n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_test_4 = torch.cat(embeddings_image_test_4)\n",
    "    logits_top1000_test_4 = torch.cat(logits_top1000_test_4)\n",
    "    inds_top1000_test_4 = torch.cat(inds_top1000_test_4)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stainless-daughter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:15:57.355564Z",
     "iopub.status.busy": "2021-09-29T19:15:57.354259Z",
     "iopub.status.idle": "2021-09-29T19:16:05.437214Z",
     "shell.execute_reply": "2021-09-29T19:16:05.435759Z",
     "shell.execute_reply.started": "2021-09-29T19:00:49.781780Z"
    },
    "papermill": {
     "duration": 8.17658,
     "end_time": "2021-09-29T19:16:05.437426",
     "exception": false,
     "start_time": "2021-09-29T19:15:57.260846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (800, 800)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c_inf800_3')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}index/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}index/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(index_df, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_index_4 = []\n",
    "    logits_top1000_index_4 = []\n",
    "    inds_top1000_index_4 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_index_4 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_index_4 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_index_4 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_index_4 = torch.cat(embeddings_image_index_4)\n",
    "    logits_top1000_index_4 = torch.cat(logits_top1000_index_4)\n",
    "    inds_top1000_index_4 = torch.cat(inds_top1000_index_4)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "young-saturday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:05.608331Z",
     "iopub.status.busy": "2021-09-29T19:16:05.607242Z",
     "iopub.status.idle": "2021-09-29T19:16:14.325095Z",
     "shell.execute_reply": "2021-09-29T19:16:14.324455Z",
     "shell.execute_reply.started": "2021-09-29T19:00:58.256914Z"
    },
    "papermill": {
     "duration": 8.811014,
     "end_time": "2021-09-29T19:16:14.325308",
     "exception": false,
     "start_time": "2021-09-29T19:16:05.514294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 eca_nfnet_l2 (800, 800)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-9c/checkpoint_last_seed587147.pth']\n",
      "../input/landmark-pp-9c/checkpoint_last_seed587147.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.50s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_9c_inf800_3')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}train/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}train/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(train, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81313\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-9c/checkpoint_*.pth'))[1:]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_train_4 = []\n",
    "    logits_top1000_train_4 = []\n",
    "    inds_top1000_train_4 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_train_4 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_train_4 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_train_4 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_train_4 = torch.cat(embeddings_image_train_4)\n",
    "    logits_top1000_train_4 = torch.cat(logits_top1000_train_4)\n",
    "    inds_top1000_train_4 = torch.cat(inds_top1000_train_4)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "classified-correction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:14.499620Z",
     "iopub.status.busy": "2021-09-29T19:16:14.498527Z",
     "iopub.status.idle": "2021-09-29T19:16:25.396767Z",
     "shell.execute_reply": "2021-09-29T19:16:25.397378Z",
     "shell.execute_reply.started": "2021-09-29T19:01:06.065022Z"
    },
    "papermill": {
     "duration": 10.994397,
     "end_time": "2021-09-29T19:16:25.397620",
     "exception": false,
     "start_time": "2021-09-29T19:16:14.403223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth']\n",
      "../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_5c_rec')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}test/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}test/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(test, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81314\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c-rec/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_test_5 = []\n",
    "    logits_top1000_test_5 = []\n",
    "    inds_top1000_test_5 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_test_5 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_test_5 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_test_5 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "        \n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_test_5 = torch.cat(embeddings_image_test_5)\n",
    "    logits_top1000_test_5 = torch.cat(logits_top1000_test_5)\n",
    "    inds_top1000_test_5 = torch.cat(inds_top1000_test_5)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "collaborative-genius",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:25.590414Z",
     "iopub.status.busy": "2021-09-29T19:16:25.587387Z",
     "iopub.status.idle": "2021-09-29T19:16:29.366277Z",
     "shell.execute_reply": "2021-09-29T19:16:29.365583Z",
     "shell.execute_reply.started": "2021-09-29T19:01:18.868072Z"
    },
    "papermill": {
     "duration": 3.881843,
     "end_time": "2021-09-29T19:16:29.366443",
     "exception": false,
     "start_time": "2021-09-29T19:16:25.484600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth']\n",
      "../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_5c_rec')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}index/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}index/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(index_df, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81314\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c-rec/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_index_5 = []\n",
    "    logits_top1000_index_5 = []\n",
    "    inds_top1000_index_5 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_index_5 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_index_5 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_index_5 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_index_5 = torch.cat(embeddings_image_index_5)\n",
    "    logits_top1000_index_5 = torch.cat(logits_top1000_index_5)\n",
    "    inds_top1000_index_5 = torch.cat(inds_top1000_index_5)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "extensive-bradford",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:29.560576Z",
     "iopub.status.busy": "2021-09-29T19:16:29.557408Z",
     "iopub.status.idle": "2021-09-29T19:16:33.136784Z",
     "shell.execute_reply": "2021-09-29T19:16:33.137545Z",
     "shell.execute_reply.started": "2021-09-29T19:01:23.195573Z"
    },
    "papermill": {
     "duration": 3.680665,
     "end_time": "2021-09-29T19:16:33.137816",
     "exception": false,
     "start_time": "2021-09-29T19:16:29.457151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_img_dyn2 base_ds_v1 tf_efficientnet_b0_ns (600, 600)\n",
      "NUM LABELS 1\n",
      "['../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth']\n",
      "../input/landmark-pp-5c-rec/checkpoint_last_seed939283.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = importlib.import_module('pp_5c_rec')\n",
    "importlib.reload(cfg)\n",
    "cfg = cfg.cfg\n",
    "print(cfg.model, cfg.dataset, cfg.backbone, cfg.img_size)\n",
    "\n",
    "cfg.data_folder = f'{COMP_FOLDER}train/'\n",
    "cfg.data_folder_test = f'{COMP_FOLDER}train/'\n",
    "\n",
    "cfg.data_dir = COMP_FOLDER\n",
    "cfg.pretrained = False\n",
    "cfg.delete_head = False\n",
    "cfg.new_old_set_weights = False\n",
    "\n",
    "ds = importlib.import_module(cfg.dataset)\n",
    "importlib.reload(ds)\n",
    "CustomDataset = ds.CustomDataset\n",
    "batch_to_device = ds.batch_to_device\n",
    "\n",
    "cfg.batch_size = 64\n",
    "cfg.pretrained_weights = None\n",
    "\n",
    "aug = cfg.val_aug\n",
    "test_ds = CustomDataset(train, cfg, aug, mode=\"test\")\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n",
    "\n",
    "test_ds.num_labels = 81314\n",
    "model = importlib.import_module(cfg.model)\n",
    "importlib.reload(model)\n",
    "Net = model.Net\n",
    "\n",
    "import glob\n",
    "state_dicts = []\n",
    "for filepath in list(glob.iglob('../input/landmark-pp-5c-rec/checkpoint_*.pth'))[:1]:\n",
    "    state_dicts.append(filepath)\n",
    "print(state_dicts)\n",
    "\n",
    "nets = []\n",
    "for sd in state_dicts[:]:\n",
    "    print(sd)\n",
    "    sd = torch.load(sd, map_location=\"cpu\")['model']\n",
    "    \n",
    "    new_d = {}\n",
    "    for k,v in sd.items():\n",
    "        new_d[k.replace(\"model.\", \"\")] = v\n",
    "    sd = new_d.copy()\n",
    "    del new_d\n",
    "    \n",
    "    net = Net(cfg, test_ds).eval().cuda()\n",
    "    net.load_state_dict(sd, strict=True)\n",
    "    \n",
    "    nets.append(net)\n",
    "    \n",
    "    del net\n",
    "    del sd\n",
    "    gc.collect()\n",
    "\n",
    "len(nets)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    embeddings_image_train_5 = []\n",
    "    logits_top1000_train_5 = []\n",
    "    inds_top1000_train_5 = []\n",
    "    for batch in tqdm(test_dl):\n",
    "\n",
    "        batch = batch_to_device(batch, DEVICE)\n",
    "        \n",
    "        embeddings_tmp = []\n",
    "        logits_top1000_tmp = []\n",
    "        inds_top1000_tmp = []\n",
    "        for net in nets:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = net(batch)\n",
    "            embeddings_tmp += [torch.nn.functional.normalize(out['embeddings'], dim=1)]\n",
    "            logits_top1000_tmp += [out['logits_top1000']]\n",
    "            inds_top1000_tmp += [out['inds_top1000']]\n",
    "\n",
    "        embeddings_image_train_5 += [torch.cat(embeddings_tmp, dim=1)]\n",
    "        logits_top1000_train_5 += [torch.cat(logits_top1000_tmp, dim=1)]\n",
    "        inds_top1000_train_5 += [torch.cat(inds_top1000_tmp, dim=1)]\n",
    "\n",
    "        del batch\n",
    "        del embeddings_tmp\n",
    "        del logits_top1000_tmp\n",
    "        del inds_top1000_tmp\n",
    "        del net\n",
    "        gc.collect()\n",
    "\n",
    "    embeddings_image_train_5 = torch.cat(embeddings_image_train_5)\n",
    "    logits_top1000_train_5 = torch.cat(logits_top1000_train_5)\n",
    "    inds_top1000_train_5 = torch.cat(inds_top1000_train_5)\n",
    "    \n",
    "del test_ds\n",
    "del test_dl\n",
    "del nets\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bottom-rally",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:33.311604Z",
     "iopub.status.busy": "2021-09-29T19:16:33.310868Z",
     "iopub.status.idle": "2021-09-29T19:16:33.430098Z",
     "shell.execute_reply": "2021-09-29T19:16:33.429036Z",
     "shell.execute_reply.started": "2021-09-29T19:01:26.552280Z"
    },
    "papermill": {
     "duration": 0.207874,
     "end_time": "2021-09-29T19:16:33.430242",
     "exception": false,
     "start_time": "2021-09-29T19:16:33.222368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_index = torch.cat([embeddings_image_index_1, embeddings_image_index_2, embeddings_image_index_3, embeddings_image_index_4, embeddings_image_index_5], dim=-1).float()\n",
    "del embeddings_image_index_1\n",
    "del embeddings_image_index_2\n",
    "del embeddings_image_index_3\n",
    "del embeddings_image_index_4\n",
    "del embeddings_image_index_5\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "framed-salon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:33.607824Z",
     "iopub.status.busy": "2021-09-29T19:16:33.606839Z",
     "iopub.status.idle": "2021-09-29T19:16:33.713960Z",
     "shell.execute_reply": "2021-09-29T19:16:33.714476Z",
     "shell.execute_reply.started": "2021-09-29T19:01:26.650772Z"
    },
    "papermill": {
     "duration": 0.198416,
     "end_time": "2021-09-29T19:16:33.714660",
     "exception": false,
     "start_time": "2021-09-29T19:16:33.516244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_test = torch.cat([embeddings_image_test_1, embeddings_image_test_2, embeddings_image_test_3, embeddings_image_test_4, embeddings_image_test_5], dim=-1).float()\n",
    "del embeddings_image_test_1\n",
    "del embeddings_image_test_2\n",
    "del embeddings_image_test_3\n",
    "del embeddings_image_test_4\n",
    "del embeddings_image_test_5\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "apart-carpet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:33.887279Z",
     "iopub.status.busy": "2021-09-29T19:16:33.886221Z",
     "iopub.status.idle": "2021-09-29T19:16:33.987709Z",
     "shell.execute_reply": "2021-09-29T19:16:33.988274Z",
     "shell.execute_reply.started": "2021-09-29T19:02:16.267474Z"
    },
    "papermill": {
     "duration": 0.190333,
     "end_time": "2021-09-29T19:16:33.988468",
     "exception": false,
     "start_time": "2021-09-29T19:16:33.798135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_train = torch.cat([embeddings_image_train_1, embeddings_image_train_2, embeddings_image_train_3, embeddings_image_train_4, embeddings_image_train_5], dim=-1).float()\n",
    "del embeddings_image_train_1\n",
    "del embeddings_image_train_2\n",
    "del embeddings_image_train_3\n",
    "del embeddings_image_train_4\n",
    "del embeddings_image_train_5\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "jewish-alaska",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:34.164700Z",
     "iopub.status.busy": "2021-09-29T19:16:34.164005Z",
     "iopub.status.idle": "2021-09-29T19:16:34.171145Z",
     "shell.execute_reply": "2021-09-29T19:16:34.170623Z",
     "shell.execute_reply.started": "2021-09-29T19:02:17.244224Z"
    },
    "papermill": {
     "duration": 0.096446,
     "end_time": "2021-09-29T19:16:34.171276",
     "exception": false,
     "start_time": "2021-09-29T19:16:34.074830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 5120])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "difficult-hardware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:34.348359Z",
     "iopub.status.busy": "2021-09-29T19:16:34.345786Z",
     "iopub.status.idle": "2021-09-29T19:16:34.350770Z",
     "shell.execute_reply": "2021-09-29T19:16:34.349056Z",
     "shell.execute_reply.started": "2021-09-29T19:02:17.692595Z"
    },
    "papermill": {
     "duration": 0.095452,
     "end_time": "2021-09-29T19:16:34.350909",
     "exception": false,
     "start_time": "2021-09-29T19:16:34.255457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 5120])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "absent-missile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:34.527721Z",
     "iopub.status.busy": "2021-09-29T19:16:34.526722Z",
     "iopub.status.idle": "2021-09-29T19:16:34.532178Z",
     "shell.execute_reply": "2021-09-29T19:16:34.531588Z",
     "shell.execute_reply.started": "2021-09-29T19:02:18.099410Z"
    },
    "papermill": {
     "duration": 0.095365,
     "end_time": "2021-09-29T19:16:34.532300",
     "exception": false,
     "start_time": "2021-09-29T19:16:34.436935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 5120])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "stylish-vietnamese",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:34.712312Z",
     "iopub.status.busy": "2021-09-29T19:16:34.711189Z",
     "iopub.status.idle": "2021-09-29T19:16:34.827765Z",
     "shell.execute_reply": "2021-09-29T19:16:34.827262Z",
     "shell.execute_reply.started": "2021-09-29T19:02:29.408009Z"
    },
    "papermill": {
     "duration": 0.212428,
     "end_time": "2021-09-29T19:16:34.827946",
     "exception": false,
     "start_time": "2021-09-29T19:16:34.615518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits_top1000_test = torch.cat([logits_top1000_test_1, logits_top1000_test_2, logits_top1000_test_3, logits_top1000_test_4, logits_top1000_test_5], dim=-1).float().detach().cpu().numpy()\n",
    "logits_top1000_index = torch.cat([logits_top1000_index_1, logits_top1000_index_2, logits_top1000_index_3, logits_top1000_index_4, logits_top1000_index_5], dim=-1).float().detach().cpu().numpy()\n",
    "logits_top1000_train = torch.cat([logits_top1000_train_1, logits_top1000_train_2, logits_top1000_train_3, logits_top1000_train_4, logits_top1000_train_5], dim=-1).float().detach().cpu().numpy()\n",
    "\n",
    "inds_top1000_test = torch.cat([inds_top1000_test_1, inds_top1000_test_2, inds_top1000_test_3, inds_top1000_test_4, inds_top1000_test_5], dim=-1).float().detach().cpu().numpy()\n",
    "inds_top1000_index = torch.cat([inds_top1000_index_1, inds_top1000_index_2, inds_top1000_index_3, inds_top1000_index_4, inds_top1000_index_5], dim=-1).float().detach().cpu().numpy()\n",
    "inds_top1000_train = torch.cat([inds_top1000_train_1, inds_top1000_train_2, inds_top1000_train_3, inds_top1000_train_4, inds_top1000_train_5], dim=-1).float().detach().cpu().numpy()\n",
    "\n",
    "del logits_top1000_test_1\n",
    "del logits_top1000_test_2\n",
    "del logits_top1000_test_3\n",
    "del logits_top1000_test_4\n",
    "del logits_top1000_test_5\n",
    "del logits_top1000_index_1\n",
    "del logits_top1000_index_2\n",
    "del logits_top1000_index_3\n",
    "del logits_top1000_index_4\n",
    "del logits_top1000_index_5\n",
    "del logits_top1000_train_1\n",
    "del logits_top1000_train_2\n",
    "del logits_top1000_train_3\n",
    "del logits_top1000_train_4\n",
    "del logits_top1000_train_5\n",
    "\n",
    "del inds_top1000_test_1\n",
    "del inds_top1000_test_2\n",
    "del inds_top1000_test_3\n",
    "del inds_top1000_test_4\n",
    "del inds_top1000_test_5\n",
    "del inds_top1000_index_1\n",
    "del inds_top1000_index_2\n",
    "del inds_top1000_index_3\n",
    "del inds_top1000_index_4\n",
    "del inds_top1000_index_5\n",
    "del inds_top1000_train_1\n",
    "del inds_top1000_train_2\n",
    "del inds_top1000_train_3\n",
    "del inds_top1000_train_4\n",
    "del inds_top1000_train_5\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "trying-austin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:35.003423Z",
     "iopub.status.busy": "2021-09-29T19:16:35.002167Z",
     "iopub.status.idle": "2021-09-29T19:16:35.051529Z",
     "shell.execute_reply": "2021-09-29T19:16:35.052110Z",
     "shell.execute_reply.started": "2021-09-29T19:02:36.830686Z"
    },
    "papermill": {
     "duration": 0.139658,
     "end_time": "2021-09-29T19:16:35.052259",
     "exception": false,
     "start_time": "2021-09-29T19:16:34.912601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find top 100 (for now, more is not needed) unique landmark inds (max blend of all models)\n",
    "inds_top1000_test_new = []\n",
    "\n",
    "for logits_top1000_test_row, inds_top1000_test_row in zip(logits_top1000_test, inds_top1000_test):\n",
    "    # print(pd.unique(inds_top1000_test_row[np.argsort(logits_top1000_test_row)[::-1]])[:100])\n",
    "    # print(logits_top1000_test_row[np.argsort(logits_top1000_test_row)[::-1]])\n",
    "    inds_top1000_test_new.append(pd.unique(inds_top1000_test_row[np.argsort(logits_top1000_test_row)[::-1]])[:100])\n",
    "    \n",
    "inds_top1000_test_new = np.array(inds_top1000_test_new)\n",
    "inds_top1000_test = inds_top1000_test_new.copy()\n",
    "\n",
    "\n",
    "inds_top1000_index_new = []\n",
    "\n",
    "for logits_top1000_index_row, inds_top1000_index_row in zip(logits_top1000_index, inds_top1000_index):\n",
    "    inds_top1000_index_new.append(pd.unique(inds_top1000_index_row[np.argsort(logits_top1000_index_row)[::-1]])[:100])\n",
    "    \n",
    "inds_top1000_index_new = np.array(inds_top1000_index_new)\n",
    "inds_top1000_index = inds_top1000_index_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "jewish-latitude",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:35.227123Z",
     "iopub.status.busy": "2021-09-29T19:16:35.226464Z",
     "iopub.status.idle": "2021-09-29T19:16:35.231418Z",
     "shell.execute_reply": "2021-09-29T19:16:35.230592Z",
     "shell.execute_reply.started": "2021-09-29T19:02:45.861996Z"
    },
    "papermill": {
     "duration": 0.093428,
     "end_time": "2021-09-29T19:16:35.231561",
     "exception": false,
     "start_time": "2021-09-29T19:16:35.138133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inds_top1000_test = inds_top1000_test_1.detach().cpu().numpy()\n",
    "# del inds_top1000_test_1\n",
    "# del inds_top1000_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "subsequent-stack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:35.411262Z",
     "iopub.status.busy": "2021-09-29T19:16:35.410588Z",
     "iopub.status.idle": "2021-09-29T19:16:35.415919Z",
     "shell.execute_reply": "2021-09-29T19:16:35.415317Z",
     "shell.execute_reply.started": "2021-09-29T19:02:46.325755Z"
    },
    "papermill": {
     "duration": 0.095473,
     "end_time": "2021-09-29T19:16:35.416050",
     "exception": false,
     "start_time": "2021-09-29T19:16:35.320577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inds_top1000_index = inds_top1000_index_1.detach().cpu().numpy()\n",
    "# del inds_top1000_index_1\n",
    "# del inds_top1000_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "nonprofit-track",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:35.597273Z",
     "iopub.status.busy": "2021-09-29T19:16:35.596196Z",
     "iopub.status.idle": "2021-09-29T19:16:36.403737Z",
     "shell.execute_reply": "2021-09-29T19:16:36.402919Z",
     "shell.execute_reply.started": "2021-09-29T19:02:47.385091Z"
    },
    "papermill": {
     "duration": 0.901657,
     "end_time": "2021-09-29T19:16:36.403983",
     "exception": false,
     "start_time": "2021-09-29T19:16:35.502326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          16015        2845        1106          16       12063       12882\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acoustic-earth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:36.582586Z",
     "iopub.status.busy": "2021-09-29T19:16:36.581820Z",
     "iopub.status.idle": "2021-09-29T19:16:36.590718Z",
     "shell.execute_reply": "2021-09-29T19:16:36.589656Z",
     "shell.execute_reply.started": "2021-09-29T19:02:51.782953Z"
    },
    "papermill": {
     "duration": 0.101357,
     "end_time": "2021-09-29T19:16:36.590843",
     "exception": false,
     "start_time": "2021-09-29T19:16:36.489486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm_matrix(m, eps=1e-8):\n",
    "    m_n = torch.linalg.norm(m, dim=1)[:, None]\n",
    "    m /= torch.max(m_n, eps * torch.ones_like(m_n))\n",
    "    return m\n",
    "\n",
    "embeddings_image_index = norm_matrix(embeddings_image_index)\n",
    "embeddings_image_test = norm_matrix(embeddings_image_test)\n",
    "embeddings_image_train = norm_matrix(embeddings_image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "premier-academy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:36.773145Z",
     "iopub.status.busy": "2021-09-29T19:16:36.771796Z",
     "iopub.status.idle": "2021-09-29T19:16:36.775524Z",
     "shell.execute_reply": "2021-09-29T19:16:36.775018Z",
     "shell.execute_reply.started": "2021-09-29T19:02:53.152251Z"
    },
    "papermill": {
     "duration": 0.096669,
     "end_time": "2021-09-29T19:16:36.775691",
     "exception": false,
     "start_time": "2021-09-29T19:16:36.679022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk = 64\n",
    "\n",
    "embeddings_image_index_chunks = embeddings_image_index.split(chunk)\n",
    "embeddings_image_test_chunks = embeddings_image_test.split(chunk)\n",
    "embeddings_image_train_chunks = embeddings_image_train.split(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "isolated-decision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:36.953782Z",
     "iopub.status.busy": "2021-09-29T19:16:36.952754Z",
     "iopub.status.idle": "2021-09-29T19:16:36.956456Z",
     "shell.execute_reply": "2021-09-29T19:16:36.955858Z",
     "shell.execute_reply.started": "2021-09-29T19:02:54.741695Z"
    },
    "papermill": {
     "duration": 0.094854,
     "end_time": "2021-09-29T19:16:36.956662",
     "exception": false,
     "start_time": "2021-09-29T19:16:36.861808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "instructional-power",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:37.260355Z",
     "iopub.status.busy": "2021-09-29T19:16:37.258898Z",
     "iopub.status.idle": "2021-09-29T19:16:37.261902Z",
     "shell.execute_reply": "2021-09-29T19:16:37.261263Z",
     "shell.execute_reply.started": "2021-09-29T19:02:56.525238Z"
    },
    "papermill": {
     "duration": 0.220119,
     "end_time": "2021-09-29T19:16:37.262059",
     "exception": false,
     "start_time": "2021-09-29T19:16:37.041940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adaptive-extension",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:37.446831Z",
     "iopub.status.busy": "2021-09-29T19:16:37.445647Z",
     "iopub.status.idle": "2021-09-29T19:16:37.560097Z",
     "shell.execute_reply": "2021-09-29T19:16:37.559588Z",
     "shell.execute_reply.started": "2021-09-29T19:04:03.334248Z"
    },
    "papermill": {
     "duration": 0.207848,
     "end_time": "2021-09-29T19:16:37.560254",
     "exception": false,
     "start_time": "2021-09-29T19:16:37.352406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n"
     ]
    }
   ],
   "source": [
    "vals_test_train = []\n",
    "inds_test_train = []\n",
    "\n",
    "for idx in tqdm(range(len(embeddings_image_test_chunks))):\n",
    "    sim_mat = torch.cdist(embeddings_image_test_chunks[idx], embeddings_image_train).float()  # .detach().cpu()\n",
    "    sim_mat = (sim_mat.float().max() - sim_mat).float()\n",
    "    sim_mat = sim_mat / (sim_mat.max() + eps)\n",
    "\n",
    "    vals_batch, inds_batch = torch.topk(sim_mat, k=TOPK, dim=1)\n",
    "\n",
    "    vals_test_train += [vals_batch.cpu()]\n",
    "    inds_test_train += [inds_batch.cpu()]\n",
    "\n",
    "    del sim_mat\n",
    "    gc.collect()\n",
    "    \n",
    "vals_test_train = torch.cat(vals_test_train)\n",
    "inds_test_train = torch.cat(inds_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "placed-philip",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:37.739394Z",
     "iopub.status.busy": "2021-09-29T19:16:37.738646Z",
     "iopub.status.idle": "2021-09-29T19:16:37.742041Z",
     "shell.execute_reply": "2021-09-29T19:16:37.742636Z",
     "shell.execute_reply.started": "2021-09-29T19:05:24.649752Z"
    },
    "papermill": {
     "duration": 0.095771,
     "end_time": "2021-09-29T19:16:37.742803",
     "exception": false,
     "start_time": "2021-09-29T19:16:37.647032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inds_test_train = inds_test_train.numpy()\n",
    "vals_test_train = vals_test_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "national-wrist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:37.926311Z",
     "iopub.status.busy": "2021-09-29T19:16:37.925633Z",
     "iopub.status.idle": "2021-09-29T19:16:37.934388Z",
     "shell.execute_reply": "2021-09-29T19:16:37.933596Z",
     "shell.execute_reply.started": "2021-09-29T19:05:33.759106Z"
    },
    "papermill": {
     "duration": 0.102297,
     "end_time": "2021-09-29T19:16:37.934580",
     "exception": false,
     "start_time": "2021-09-29T19:16:37.832283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "num_good_match = (vals_test_train[i] > 0.5).sum()\n",
    "print(num_good_match)\n",
    "print(embeddings_image_train[inds_test_train[i][:num_good_match]].mean(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "laughing-spyware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:38.115760Z",
     "iopub.status.busy": "2021-09-29T19:16:38.114752Z",
     "iopub.status.idle": "2021-09-29T19:16:38.128616Z",
     "shell.execute_reply": "2021-09-29T19:16:38.128089Z",
     "shell.execute_reply.started": "2021-09-29T19:05:59.325854Z"
    },
    "papermill": {
     "duration": 0.107352,
     "end_time": "2021-09-29T19:16:38.128830",
     "exception": false,
     "start_time": "2021-09-29T19:16:38.021478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 8061.71it/s]\n"
     ]
    }
   ],
   "source": [
    "## take mean average of test embedding with nearest neighbor from train\n",
    "for i in tqdm(range(len(inds_test_train))):\n",
    "    if vals_test_train[i][0] > 0.5:\n",
    "        num_good_match = (vals_test_train[i] > 0.5).sum()\n",
    "        embeddings_image_test[i] = (embeddings_image_test[i] + embeddings_image_train[inds_test_train[i][:num_good_match]].mean(0)) / (num_good_match + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "worldwide-wagon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:38.419812Z",
     "iopub.status.busy": "2021-09-29T19:16:38.418882Z",
     "iopub.status.idle": "2021-09-29T19:16:38.422679Z",
     "shell.execute_reply": "2021-09-29T19:16:38.422129Z",
     "shell.execute_reply.started": "2021-09-29T19:10:44.223617Z"
    },
    "papermill": {
     "duration": 0.204769,
     "end_time": "2021-09-29T19:16:38.422894",
     "exception": false,
     "start_time": "2021-09-29T19:16:38.218125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del embeddings_image_train\n",
    "del logits_top1000_train\n",
    "del inds_top1000_train\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sharing-architect",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:38.606219Z",
     "iopub.status.busy": "2021-09-29T19:16:38.605523Z",
     "iopub.status.idle": "2021-09-29T19:16:38.611453Z",
     "shell.execute_reply": "2021-09-29T19:16:38.610547Z",
     "shell.execute_reply.started": "2021-09-29T19:06:08.342793Z"
    },
    "papermill": {
     "duration": 0.100089,
     "end_time": "2021-09-29T19:16:38.611673",
     "exception": false,
     "start_time": "2021-09-29T19:16:38.511584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_image_test = norm_matrix(embeddings_image_test)\n",
    "embeddings_image_test_chunks = embeddings_image_test.split(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "seasonal-carpet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:38.798469Z",
     "iopub.status.busy": "2021-09-29T19:16:38.797501Z",
     "iopub.status.idle": "2021-09-29T19:16:38.919692Z",
     "shell.execute_reply": "2021-09-29T19:16:38.920397Z",
     "shell.execute_reply.started": "2021-09-29T19:06:23.617168Z"
    },
    "papermill": {
     "duration": 0.220554,
     "end_time": "2021-09-29T19:16:38.920664",
     "exception": false,
     "start_time": "2021-09-29T19:16:38.700110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.87it/s]\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "inds = []\n",
    "\n",
    "for idx in tqdm(range(len(embeddings_image_test_chunks))):\n",
    "    sim_mat = torch.cdist(embeddings_image_test_chunks[idx], embeddings_image_index).float()  # .detach().cpu()\n",
    "    sim_mat = (sim_mat.float().max() - sim_mat).float()\n",
    "    sim_mat = sim_mat / (sim_mat.max() + eps)\n",
    "\n",
    "    vals_batch, inds_batch = torch.topk(sim_mat, k=TOPK, dim=1)\n",
    "\n",
    "    vals += [vals_batch.cpu()]\n",
    "    inds += [inds_batch.cpu()]\n",
    "\n",
    "    del sim_mat\n",
    "    gc.collect()\n",
    "    \n",
    "vals = torch.cat(vals)\n",
    "inds = torch.cat(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "super-camping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:39.112565Z",
     "iopub.status.busy": "2021-09-29T19:16:39.111503Z",
     "iopub.status.idle": "2021-09-29T19:16:39.235065Z",
     "shell.execute_reply": "2021-09-29T19:16:39.232703Z",
     "shell.execute_reply.started": "2021-09-29T19:06:32.353891Z"
    },
    "papermill": {
     "duration": 0.221256,
     "end_time": "2021-09-29T19:16:39.235275",
     "exception": false,
     "start_time": "2021-09-29T19:16:39.014019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n"
     ]
    }
   ],
   "source": [
    "vals_index = []\n",
    "inds_index = []\n",
    "\n",
    "for idx in tqdm(range(len(embeddings_image_index_chunks))):\n",
    "    sim_mat = torch.cdist(embeddings_image_index_chunks[idx], embeddings_image_index).float().detach().cpu()\n",
    "    sim_mat = (sim_mat.float().max() - sim_mat).float()\n",
    "    sim_mat = sim_mat / (sim_mat.max() + eps)\n",
    "\n",
    "    # remove the self match! -> set sim_mat to 0\n",
    "    sim_mat[:, int(idx*chunk):int((idx+1)*chunk)] = torch.minimum(1 - torch.eye(len(sim_mat)), sim_mat[:, int(idx*chunk):int((idx+1)*chunk)])\n",
    "\n",
    "    vals_batch, inds_batch = torch.topk(sim_mat, k=TOPK, dim=1)\n",
    "\n",
    "    vals_index += [vals_batch.cpu()]\n",
    "    inds_index += [inds_batch.cpu()]\n",
    "\n",
    "    del sim_mat\n",
    "    gc.collect()\n",
    "    \n",
    "vals_index = torch.cat(vals_index)\n",
    "inds_index = torch.cat(inds_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "powered-finding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:39.526607Z",
     "iopub.status.busy": "2021-09-29T19:16:39.525407Z",
     "iopub.status.idle": "2021-09-29T19:16:39.530612Z",
     "shell.execute_reply": "2021-09-29T19:16:39.530041Z",
     "shell.execute_reply.started": "2021-09-29T19:10:48.899490Z"
    },
    "papermill": {
     "duration": 0.203639,
     "end_time": "2021-09-29T19:16:39.530802",
     "exception": false,
     "start_time": "2021-09-29T19:16:39.327163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del embeddings_image_index\n",
    "del embeddings_image_test\n",
    "del embeddings_image_test_chunks\n",
    "del embeddings_image_index_chunks\n",
    "\n",
    "del vals_batch\n",
    "del inds_batch\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "junior-gravity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:39.728475Z",
     "iopub.status.busy": "2021-09-29T19:16:39.727054Z",
     "iopub.status.idle": "2021-09-29T19:16:39.741878Z",
     "shell.execute_reply": "2021-09-29T19:16:39.742740Z",
     "shell.execute_reply.started": "2021-09-29T19:10:52.191213Z"
    },
    "papermill": {
     "duration": 0.118758,
     "end_time": "2021-09-29T19:16:39.742999",
     "exception": false,
     "start_time": "2021-09-29T19:16:39.624241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals = vals.numpy()\n",
    "inds = inds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "instrumental-disney",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:40.092533Z",
     "iopub.status.busy": "2021-09-29T19:16:40.091463Z",
     "iopub.status.idle": "2021-09-29T19:16:40.093644Z",
     "shell.execute_reply": "2021-09-29T19:16:40.095251Z",
     "shell.execute_reply.started": "2021-09-29T19:10:52.863748Z"
    },
    "papermill": {
     "duration": 0.169658,
     "end_time": "2021-09-29T19:16:40.095469",
     "exception": false,
     "start_time": "2021-09-29T19:16:39.925811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals_index = vals_index.numpy()\n",
    "inds_index = inds_index.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "noted-security",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:40.400060Z",
     "iopub.status.busy": "2021-09-29T19:16:40.399101Z",
     "iopub.status.idle": "2021-09-29T19:16:40.403579Z",
     "shell.execute_reply": "2021-09-29T19:16:40.404227Z",
     "shell.execute_reply.started": "2021-09-29T19:10:54.134717Z"
    },
    "papermill": {
     "duration": 0.151718,
     "end_time": "2021-09-29T19:16:40.404362",
     "exception": false,
     "start_time": "2021-09-29T19:16:40.252644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 13, 10,  9,  1, 17, 22, 14, 49, 37, 36, 30,  2,  5, 28, 32,\n",
       "        50, 46, 45, 43, 19, 11, 21,  7, 15, 20, 23, 31, 24, 42, 16, 48,\n",
       "        33,  0, 35, 41, 40, 26, 29,  6,  3,  8, 44, 47, 12,  4, 18, 25,\n",
       "        27, 39, 38],\n",
       "       [23,  9, 20, 13, 25, 44, 47, 34, 50, 41, 35, 17,  5,  2, 45,  1,\n",
       "         7, 48, 26, 49,  4, 43, 19,  6,  8, 38, 16, 12, 42, 40,  3, 11,\n",
       "        18, 33, 46, 32, 39, 28, 31, 15, 27, 24, 30, 10, 14, 29, 22, 36,\n",
       "        21, 37,  0],\n",
       "       [27, 23, 18, 50, 39, 10, 30, 33, 15, 14, 46, 38, 35, 34, 22, 44,\n",
       "        12,  9, 16,  4, 28, 21, 29,  1, 48, 45,  5,  7, 25, 43, 42,  0,\n",
       "        49, 36, 40, 37, 31, 17, 20,  8, 32, 11, 41,  3, 13,  6,  2, 19,\n",
       "        24, 47, 26]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "trained-pillow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:40.592668Z",
     "iopub.status.busy": "2021-09-29T19:16:40.591648Z",
     "iopub.status.idle": "2021-09-29T19:16:40.596381Z",
     "shell.execute_reply": "2021-09-29T19:16:40.597059Z",
     "shell.execute_reply.started": "2021-09-29T19:10:54.542087Z"
    },
    "papermill": {
     "duration": 0.103013,
     "end_time": "2021-09-29T19:16:40.597201",
     "exception": false,
     "start_time": "2021-09-29T19:16:40.494188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52, 0.34, 0.32, 0.3 , 0.3 , 0.29, 0.29, 0.29, 0.29, 0.29, 0.29,\n",
       "        0.28, 0.27, 0.27, 0.26, 0.26, 0.26, 0.26, 0.25, 0.25, 0.25, 0.25,\n",
       "        0.25, 0.25, 0.25, 0.25, 0.24, 0.24, 0.24, 0.23, 0.23, 0.23, 0.23,\n",
       "        0.22, 0.22, 0.22, 0.22, 0.22, 0.21, 0.21, 0.21, 0.21, 0.2 , 0.2 ,\n",
       "        0.19, 0.19, 0.19, 0.18, 0.17, 0.15, 0.15],\n",
       "       [0.41, 0.41, 0.38, 0.36, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.34,\n",
       "        0.34, 0.33, 0.33, 0.33, 0.33, 0.3 , 0.3 , 0.3 , 0.3 , 0.29, 0.29,\n",
       "        0.28, 0.27, 0.27, 0.27, 0.27, 0.26, 0.26, 0.26, 0.25, 0.25, 0.25,\n",
       "        0.24, 0.24, 0.24, 0.23, 0.23, 0.23, 0.22, 0.22, 0.22, 0.21, 0.2 ,\n",
       "        0.2 , 0.19, 0.19, 0.19, 0.17, 0.13, 0.11],\n",
       "       [0.42, 0.4 , 0.36, 0.34, 0.33, 0.32, 0.31, 0.3 , 0.3 , 0.3 , 0.29,\n",
       "        0.29, 0.29, 0.29, 0.29, 0.28, 0.28, 0.28, 0.28, 0.27, 0.27, 0.26,\n",
       "        0.26, 0.26, 0.26, 0.25, 0.25, 0.25, 0.25, 0.24, 0.24, 0.24, 0.24,\n",
       "        0.23, 0.23, 0.23, 0.23, 0.23, 0.22, 0.22, 0.22, 0.22, 0.21, 0.21,\n",
       "        0.19, 0.19, 0.17, 0.17, 0.17, 0.15, 0.15]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "creative-agency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:40.798847Z",
     "iopub.status.busy": "2021-09-29T19:16:40.797867Z",
     "iopub.status.idle": "2021-09-29T19:16:40.826549Z",
     "shell.execute_reply": "2021-09-29T19:16:40.825714Z",
     "shell.execute_reply.started": "2021-09-29T19:11:07.211333Z"
    },
    "papermill": {
     "duration": 0.139643,
     "end_time": "2021-09-29T19:16:40.826742",
     "exception": false,
     "start_time": "2021-09-29T19:16:40.687099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# If one index image is predicted very often as rank1 or 2?, dampen the score of this image\n",
    "rank1_top_preds = pd.value_counts(inds[:, 0:100].flatten())\n",
    "# rank2_top_preds = pd.value_counts(inds[:, 1])\n",
    "\n",
    "for top1_pred in tqdm(rank1_top_preds[rank1_top_preds > 70].index):\n",
    "    for i in range(len(inds)):\n",
    "        new_inds = inds[i].copy()\n",
    "        new_vals = vals[i].copy()\n",
    "    \n",
    "        found_at_id = np.where(inds[i] == top1_pred)[0]\n",
    "        if len(found_at_id > 0):\n",
    "            found_at_id = found_at_id[0]\n",
    "            new_vals[found_at_id] *= 0.90  # dampen sample that appears very often as top prediction\n",
    "\n",
    "            new_inds = new_inds[np.argsort(new_vals)[::-1]]  # re sort\n",
    "            new_vals = new_vals[np.argsort(new_vals)[::-1]]  # re sort\n",
    "\n",
    "            inds[i] = new_inds[:TOPK]\n",
    "            vals[i] = new_vals[:TOPK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "wound-laser",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:41.023593Z",
     "iopub.status.busy": "2021-09-29T19:16:41.022560Z",
     "iopub.status.idle": "2021-09-29T19:16:41.034586Z",
     "shell.execute_reply": "2021-09-29T19:16:41.036208Z",
     "shell.execute_reply.started": "2021-09-29T19:11:12.226332Z"
    },
    "papermill": {
     "duration": 0.117605,
     "end_time": "2021-09-29T19:16:41.036451",
     "exception": false,
     "start_time": "2021-09-29T19:16:40.918846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 13081.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Boost vals if the matched index is the same landmark (highest proba)\n",
    "\n",
    "for i in tqdm(range(len(inds))):\n",
    "    new_inds = inds[i].copy()\n",
    "    new_vals = vals[i].copy()\n",
    "    \n",
    "    landmark_with_highest_proba = inds_top1000_test[i][0]\n",
    "    found_matches = np.where(inds_top1000_index[:, 0] == landmark_with_highest_proba)[0]\n",
    "    # print(found_matches)\n",
    "    for found_match in found_matches:\n",
    "        if found_match in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == found_match)[0][0]\n",
    "            # print(found_at_id)\n",
    "            new_vals[found_at_id] *= 1.8\n",
    "        else:  # add all other index images that have this landmark on rank1 to the vals/inds\n",
    "            new_vals = np.append(new_vals, np.median(new_vals[:40]))\n",
    "            new_inds = np.append(new_inds, found_match)\n",
    "\n",
    "    landmark_with_2ndhighest_proba = inds_top1000_test[i][1]\n",
    "    found_matches = np.where(inds_top1000_index[:, 0] == landmark_with_2ndhighest_proba)[0]\n",
    "    # print(found_matches)\n",
    "    for found_match in found_matches:\n",
    "        if found_match in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == found_match)[0][0]\n",
    "            # print(found_at_id)\n",
    "            new_vals[found_at_id] *= 1.3\n",
    "\n",
    "    landmark_with_3rdhighest_proba = inds_top1000_test[i][2]\n",
    "    found_matches = np.where(inds_top1000_index[:, 0] == landmark_with_3rdhighest_proba)[0]\n",
    "    # print(found_matches)\n",
    "    for found_match in found_matches:\n",
    "        if found_match in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == found_match)[0][0]\n",
    "            # print(found_at_id)\n",
    "            new_vals[found_at_id] *= 1.05\n",
    "\n",
    "    new_inds = new_inds[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    new_vals = new_vals[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    \n",
    "    inds[i] = new_inds[:TOPK]\n",
    "    vals[i] = new_vals[:TOPK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "jewish-calendar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:41.242781Z",
     "iopub.status.busy": "2021-09-29T19:16:41.236192Z",
     "iopub.status.idle": "2021-09-29T19:16:41.333290Z",
     "shell.execute_reply": "2021-09-29T19:16:41.334137Z",
     "shell.execute_reply.started": "2021-09-29T19:11:19.538062Z"
    },
    "papermill": {
     "duration": 0.200292,
     "end_time": "2021-09-29T19:16:41.334378",
     "exception": false,
     "start_time": "2021-09-29T19:16:41.134086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 622.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Boost vals if they are in the top of the 3 best matched sample as well, if not add with ~rank50 guess\n",
    "\n",
    "for i in tqdm(range(len(inds))):\n",
    "    new_inds = inds[i].copy()\n",
    "    new_vals = vals[i].copy()\n",
    "    \n",
    "    gain = vals_index[inds[i][0]][:50]\n",
    "    gain_d = vals_index[inds[i][0]][:50] - vals_index[inds[i][0]][1:51]  # top50 distance to next match\n",
    "    gains = (gain * gain_d).copy()\n",
    "    gains *= 15\n",
    "    # gains = np.sort(gains)[::-1]\n",
    "    # print(gains)\n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][0]][:50]):  # top 50 of best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1 + gains[j]  # boost depending on distance to next match\n",
    "#         else:\n",
    "#             new_vals = np.append(new_vals, np.median(new_vals[:1000] * (1 + gains[j])))\n",
    "#             new_inds = np.append(new_inds, boost_sample)\n",
    "\n",
    "    gain = vals_index[inds[i][1]][:10]\n",
    "    gain_d = vals_index[inds[i][1]][:10] - vals_index[inds[i][1]][1:11]  # top10 distance to next match\n",
    "    gains = (gain * gain_d).copy()\n",
    "    gains *= 4\n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][1]][:10]):  # top 10 of second best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1 + gains[j]  # boost by 20% - 0% (depending on rank position)\n",
    "\n",
    "    gain = vals_index[inds[i][2]][:5]\n",
    "    gain_d = vals_index[inds[i][2]][:5] - vals_index[inds[i][2]][1:6]  # top5 distance to next match\n",
    "    gains = (gain * gain_d).copy()\n",
    "    gains *= 2\n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][2]][:5]):  # top 5 of third best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1 + gains[j]  # boost by 10% - 0% (depending on rank position)\n",
    "            \n",
    "    new_inds = new_inds[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    new_vals = new_vals[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    \n",
    "    inds[i] = new_inds[:TOPK]\n",
    "    vals[i] = new_vals[:TOPK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "minor-iceland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:41.534172Z",
     "iopub.status.busy": "2021-09-29T19:16:41.532746Z",
     "iopub.status.idle": "2021-09-29T19:16:41.596098Z",
     "shell.execute_reply": "2021-09-29T19:16:41.595568Z",
     "shell.execute_reply.started": "2021-09-29T19:11:25.033282Z"
    },
    "papermill": {
     "duration": 0.166307,
     "end_time": "2021-09-29T19:16:41.596221",
     "exception": false,
     "start_time": "2021-09-29T19:16:41.429914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 961.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dampen vals, if there is no overlap of topX predicted landmark between test and index\n",
    "\n",
    "# vals = vals_backup.copy()\n",
    "# inds = inds_backup.copy()\n",
    "\n",
    "OVERLAP_CHECK_1 = 3\n",
    "DAMPING_OVERLAP_1 = 0.7\n",
    "\n",
    "OVERLAP_CHECK_2 = 8\n",
    "DAMPING_OVERLAP_2 = 0.8\n",
    "\n",
    "for i in tqdm(range(len(inds))):\n",
    "    new_inds = inds[i].copy()\n",
    "    new_vals = vals[i].copy()\n",
    "    \n",
    "    top10_landmarks_test_1 = set(inds_top1000_test[i][:OVERLAP_CHECK_1])\n",
    "    top10_landmarks_test_2 = set(inds_top1000_test[i][:OVERLAP_CHECK_2])\n",
    "    \n",
    "    # print(found_matches)\n",
    "    for j, id_to_check in enumerate(new_inds):\n",
    "        top10_landmarks_id_to_check = set(inds_top1000_index[id_to_check, :OVERLAP_CHECK_1])\n",
    "        overlap = OVERLAP_CHECK_1 - len(top10_landmarks_test_1 - top10_landmarks_id_to_check)\n",
    "        if overlap == 0:\n",
    "            # print(\"no overlap\")\n",
    "            new_vals[j] *= DAMPING_OVERLAP_1\n",
    "\n",
    "        top10_landmarks_id_to_check = set(inds_top1000_index[id_to_check, :OVERLAP_CHECK_2])\n",
    "        overlap = OVERLAP_CHECK_2 - len(top10_landmarks_test_2 - top10_landmarks_id_to_check)\n",
    "        if overlap == 0:\n",
    "            # print(\"no overlap\")\n",
    "            new_vals[j] *= DAMPING_OVERLAP_2\n",
    "\n",
    "    new_inds = new_inds[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    new_vals = new_vals[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    \n",
    "    inds[i] = new_inds[:TOPK]\n",
    "    vals[i] = new_vals[:TOPK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "played-reaction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:41.795761Z",
     "iopub.status.busy": "2021-09-29T19:16:41.794593Z",
     "iopub.status.idle": "2021-09-29T19:16:41.874340Z",
     "shell.execute_reply": "2021-09-29T19:16:41.875993Z",
     "shell.execute_reply.started": "2021-09-29T19:11:27.465421Z"
    },
    "papermill": {
     "duration": 0.185786,
     "end_time": "2021-09-29T19:16:41.876374",
     "exception": false,
     "start_time": "2021-09-29T19:16:41.690588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 765.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Boost vals if they are in the top of the 3 best matched sample as well, if not add with ~rank50 guess\n",
    "\n",
    "for i in tqdm(range(len(inds))):\n",
    "    new_inds = inds[i].copy()\n",
    "    new_vals = vals[i].copy()\n",
    "    \n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][0]][:20]):  # top 20 of best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1.4 - (j * 0.02)  # boost by 40% - 0% (depending on rank position)\n",
    "        elif j < 5:\n",
    "            new_vals = np.append(new_vals, np.median(new_vals[:40] - (j * 0.02)))\n",
    "            new_inds = np.append(new_inds, boost_sample)\n",
    "\n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][1]][:10]):  # top 10 of second best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1.2 - (j * 0.02)  # boost by 20% - 0% (depending on rank position)\n",
    "            \n",
    "    for j, boost_sample in enumerate(inds_index[inds[i][2]][:5]):  # top 5 of third best matched sample\n",
    "        if boost_sample in inds[i]:\n",
    "            found_at_id = np.where(inds[i] == boost_sample)[0][0]\n",
    "            new_vals[found_at_id] *= 1.1 - (j * 0.02)  # boost by 10% - 0% (depending on rank position)\n",
    "            \n",
    "    new_inds = new_inds[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    new_vals = new_vals[np.argsort(new_vals)[::-1]]  # re sort\n",
    "    \n",
    "    inds[i] = new_inds[:TOPK]\n",
    "    vals[i] = new_vals[:TOPK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "lucky-gibson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:42.255701Z",
     "iopub.status.busy": "2021-09-29T19:16:42.254470Z",
     "iopub.status.idle": "2021-09-29T19:16:42.261562Z",
     "shell.execute_reply": "2021-09-29T19:16:42.260698Z",
     "shell.execute_reply.started": "2021-09-29T19:11:32.937080Z"
    },
    "papermill": {
     "duration": 0.204675,
     "end_time": "2021-09-29T19:16:42.261851",
     "exception": false,
     "start_time": "2021-09-29T19:16:42.057176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inds = inds[:, :100]\n",
    "vals = vals[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "practical-found",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:42.623901Z",
     "iopub.status.busy": "2021-09-29T19:16:42.623144Z",
     "iopub.status.idle": "2021-09-29T19:16:42.985965Z",
     "shell.execute_reply": "2021-09-29T19:16:42.987238Z",
     "shell.execute_reply.started": "2021-09-29T19:11:36.264644Z"
    },
    "papermill": {
     "duration": 0.545007,
     "end_time": "2021-09-29T19:16:42.987495",
     "exception": false,
     "start_time": "2021-09-29T19:16:42.442488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PUBLIC_RUN and FAST_COMMIT:\n",
    "    sub = pd.read_csv(\"../input/landmark-retrieval-2021/sample_submission.csv\")\n",
    "    sub.to_csv('submission.csv',index=False)\n",
    "else:\n",
    "    sub = pd.DataFrame({\"id\": test_ids})\n",
    "    preds_string = []\n",
    "\n",
    "    for i in tqdm(range(len(sub))):\n",
    "        p = pd.unique(np.array(index_ids)[inds[i]])\n",
    "        preds_string += [' '.join(p)]\n",
    "\n",
    "    sub[\"images\"] = preds_string\n",
    "    sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "homeless-vocabulary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T19:16:43.220782Z",
     "iopub.status.busy": "2021-09-29T19:16:43.219675Z",
     "iopub.status.idle": "2021-09-29T19:16:43.229584Z",
     "shell.execute_reply": "2021-09-29T19:16:43.230099Z",
     "shell.execute_reply.started": "2021-09-29T19:11:36.936051Z"
    },
    "papermill": {
     "duration": 0.121621,
     "end_time": "2021-09-29T19:16:43.230244",
     "exception": false,
     "start_time": "2021-09-29T19:16:43.108623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00084cdf8f600d00</td>\n",
       "      <td>39ff080e3b9e37d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00141b8a5a729084</td>\n",
       "      <td>d75e248790c371d4 a0a13eb5924b395c 49dac2cf6777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0044d82ea7654ece</td>\n",
       "      <td>80f1aba556c3de4e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00d5b448fa93e1b8</td>\n",
       "      <td>2c6f6cbaa3f586c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>012436be7f659057</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>ff06f084134f4df6</td>\n",
       "      <td>acd395de725c6ffa 0adc1ff5ed5df4b5 4b57b48ac2b7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>ff4135c3071f7b36</td>\n",
       "      <td>216d1bea7a259232 067a42c02294ce2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>ff8b519e7dfc5506</td>\n",
       "      <td>59ca927b6e0c8a7a 452a2125ea39a713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>ffb08958f4e67f61</td>\n",
       "      <td>b6b5c29be4dd342d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>ffb4bfd04f23dee7</td>\n",
       "      <td>15a18361cd04474a 903dc20092c78b11 487ec2e66189...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                             images\n",
       "0     00084cdf8f600d00                                   39ff080e3b9e37d9\n",
       "1     00141b8a5a729084  d75e248790c371d4 a0a13eb5924b395c 49dac2cf6777...\n",
       "2     0044d82ea7654ece                                   80f1aba556c3de4e\n",
       "3     00d5b448fa93e1b8                                   2c6f6cbaa3f586c6\n",
       "4     012436be7f659057                                                NaN\n",
       "...                ...                                                ...\n",
       "1124  ff06f084134f4df6  acd395de725c6ffa 0adc1ff5ed5df4b5 4b57b48ac2b7...\n",
       "1125  ff4135c3071f7b36                  216d1bea7a259232 067a42c02294ce2c\n",
       "1126  ff8b519e7dfc5506                  59ca927b6e0c8a7a 452a2125ea39a713\n",
       "1127  ffb08958f4e67f61                                   b6b5c29be4dd342d\n",
       "1128  ffb4bfd04f23dee7  15a18361cd04474a 903dc20092c78b11 487ec2e66189...\n",
       "\n",
       "[1129 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-worse",
   "metadata": {
    "papermill": {
     "duration": 0.103031,
     "end_time": "2021-09-29T19:16:43.433712",
     "exception": false,
     "start_time": "2021-09-29T19:16:43.330681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 202.585306,
   "end_time": "2021-09-29T19:16:44.746293",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-29T19:13:22.160987",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
