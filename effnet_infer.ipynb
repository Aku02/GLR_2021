{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012664,
     "end_time": "2021-08-28T18:36:34.916317",
     "exception": false,
     "start_time": "2021-08-28T18:36:34.903653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Private 0.51+ and Public 0.54+ kernel with some straightforward methodologies\n",
    "\n",
    "\n",
    "**How we approach:**\n",
    "\n",
    "When this competition first launch, we just fiddled and played around with the parameters of the original baseline. \n",
    "\n",
    "After several weeks, thanks to [Ragnar's](http://www.kaggle.com/ragnar123) awesome kernel of training Effnet, we find some practical ways to train our own models. After reading Keetar's fantastic writeup of his GLD retrieval, we trained our Effnet B6 and B7 first with 384 sized images. CV is 0.84 and 0.85 respectively. Then we use the increasing 512 sized images to further tuned our B6 and B7. Training environment is Colab Pro. Then we simply put the two model ensembling predictions to the golbal features extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:36:34.945555Z",
     "iopub.status.busy": "2021-08-28T18:36:34.944790Z",
     "iopub.status.idle": "2021-08-28T18:37:28.461937Z",
     "shell.execute_reply": "2021-08-28T18:37:28.462433Z",
     "shell.execute_reply.started": "2021-08-27T17:30:54.260214Z"
    },
    "papermill": {
     "duration": 53.534939,
     "end_time": "2021-08-28T18:37:28.462626",
     "exception": false,
     "start_time": "2021-08-28T18:36:34.927687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/glrec2020/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.14.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/glrec2020/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.16.2)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.8.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.14.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/glrec2020/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/glrec2020/efficientnet-1.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:28.499030Z",
     "iopub.status.busy": "2021-08-28T18:37:28.498221Z",
     "iopub.status.idle": "2021-08-28T18:37:33.743915Z",
     "shell.execute_reply": "2021-08-28T18:37:33.742487Z",
     "shell.execute_reply.started": "2021-08-27T17:31:48.369943Z"
    },
    "papermill": {
     "duration": 5.266345,
     "end_time": "2021-08-28T18:37:33.744062",
     "exception": false,
     "start_time": "2021-08-28T18:37:28.477717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import gc\n",
    "import pathlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy import spatial\n",
    "import cv2\n",
    "import efficientnet.tfkeras as efn\n",
    "import math\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import pydegensac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:33.778701Z",
     "iopub.status.busy": "2021-08-28T18:37:33.777002Z",
     "iopub.status.idle": "2021-08-28T18:37:33.779310Z",
     "shell.execute_reply": "2021-08-28T18:37:33.779724Z",
     "shell.execute_reply.started": "2021-08-27T17:31:54.303656Z"
    },
    "papermill": {
     "duration": 0.021334,
     "end_time": "2021-08-28T18:37:33.779826",
     "exception": false,
     "start_time": "2021-08-28T18:37:33.758492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 81313\n",
    "IMAGE_SIZE = [384, 384]\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:33.828444Z",
     "iopub.status.busy": "2021-08-28T18:37:33.812209Z",
     "iopub.status.idle": "2021-08-28T18:37:33.846258Z",
     "shell.execute_reply": "2021-08-28T18:37:33.845837Z",
     "shell.execute_reply.started": "2021-08-27T17:31:54.311322Z"
    },
    "papermill": {
     "duration": 0.050984,
     "end_time": "2021-08-28T18:37:33.846358",
     "exception": false,
     "start_time": "2021-08-28T18:37:33.795374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "\n",
    "# Function to build our model using fine tunning (efficientnet)\n",
    "def get_model_B6():\n",
    "\n",
    "    margin = ArcMarginProduct(\n",
    "        n_classes = NUMBER_OF_CLASSES, \n",
    "        s = 64, \n",
    "        m = 0.15, \n",
    "        name='head/arc_margin', \n",
    "        dtype='float32'\n",
    "        )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (384, 384, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x4 = efn.EfficientNetB6(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x4)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = margin([x, label])\n",
    "\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = opt,\n",
    "        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "        ) \n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_B7():\n",
    "\n",
    "    margin = ArcMarginProduct(\n",
    "        n_classes = NUMBER_OF_CLASSES, \n",
    "        s = 64, \n",
    "        m = 0.15, \n",
    "        name='head/arc_margin', \n",
    "        dtype='float32'\n",
    "        )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (384, 384, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x4 = efn.EfficientNetB7(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x4)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = margin([x, label])\n",
    "\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = opt,\n",
    "        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "        ) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:33.879849Z",
     "iopub.status.busy": "2021-08-28T18:37:33.879160Z",
     "iopub.status.idle": "2021-08-28T18:37:51.148957Z",
     "shell.execute_reply": "2021-08-28T18:37:51.147624Z",
     "shell.execute_reply.started": "2021-08-27T17:31:54.354893Z"
    },
    "papermill": {
     "duration": 17.288321,
     "end_time": "2021-08-28T18:37:51.149099",
     "exception": false,
     "start_time": "2021-08-28T18:37:33.860778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL1 = get_model_B6()\n",
    "MODEL2 = get_model_B7()\n",
    "\n",
    "# MODEL1.load_weights('../input/effb6-512-ep18/effb6model512-18.h5')\n",
    "# MODEL1 = tf.keras.models.Model(inputs = MODEL1.input[0], outputs = MODEL1.layers[-4].output)\n",
    "\n",
    "MODEL2.load_weights('../input/effb7-512-ep12/effb7model512-12.h5')\n",
    "MODEL2 = tf.keras.models.Model(inputs = MODEL2.input[0], outputs = MODEL2.layers[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.183760Z",
     "iopub.status.busy": "2021-08-28T18:37:51.182926Z",
     "iopub.status.idle": "2021-08-28T18:37:51.261035Z",
     "shell.execute_reply": "2021-08-28T18:37:51.261648Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.755193Z"
    },
    "papermill": {
     "duration": 0.09735,
     "end_time": "2021-08-28T18:37:51.261795",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.164445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inp1 (InputLayer)            [(None, 384, 384, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b7 (Functional) (None, None, None, 2560)  64097680  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1311232   \n",
      "=================================================================\n",
      "Total params: 65,408,912\n",
      "Trainable params: 65,098,192\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.297547Z",
     "iopub.status.busy": "2021-08-28T18:37:51.296157Z",
     "iopub.status.idle": "2021-08-28T18:37:51.298831Z",
     "shell.execute_reply": "2021-08-28T18:37:51.299321Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.833876Z"
    },
    "papermill": {
     "duration": 0.021836,
     "end_time": "2021-08-28T18:37:51.299429",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.277593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TO_RERANK = 3 #originally 5\n",
    "NUM_PUBLIC_TEST_IMAGES = 10345 # Used to detect if in session or re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.336484Z",
     "iopub.status.busy": "2021-08-28T18:37:51.335801Z",
     "iopub.status.idle": "2021-08-28T18:37:51.339101Z",
     "shell.execute_reply": "2021-08-28T18:37:51.339497Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.840424Z"
    },
    "papermill": {
     "duration": 0.02556,
     "end_time": "2021-08-28T18:37:51.339600",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.314040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(image_path, size = (384, 384)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, size)\n",
    "    img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (512, 512))\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.reshape(img, [1, 512, 512, 3])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.378764Z",
     "iopub.status.busy": "2021-08-28T18:37:51.376910Z",
     "iopub.status.idle": "2021-08-28T18:37:51.379496Z",
     "shell.execute_reply": "2021-08-28T18:37:51.379931Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.853037Z"
    },
    "papermill": {
     "duration": 0.02452,
     "end_time": "2021-08-28T18:37:51.380042",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.355522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join('..', 'input')\n",
    "\n",
    "DATASET_DIR = os.path.join(INPUT_DIR, 'landmark-recognition-2021')\n",
    "TEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "TRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "TRAIN_LABELMAP_PATH = os.path.join(DATASET_DIR, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.414943Z",
     "iopub.status.busy": "2021-08-28T18:37:51.414404Z",
     "iopub.status.idle": "2021-08-28T18:37:51.418592Z",
     "shell.execute_reply": "2021-08-28T18:37:51.418167Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.863075Z"
    },
    "papermill": {
     "duration": 0.02376,
     "end_time": "2021-08-28T18:37:51.418672",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.394912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_PUBLIC_TRAIN_IMAGES = 1580470 # Used to detect if in session or re-run.\n",
    "MAX_NUM_EMBEDDINGS = -1  # Set to > 1 to subsample dataset while debugging.\n",
    "\n",
    "# Retrieval & re-ranking parameters:\n",
    "NUM_TO_RERANK = 3\n",
    "TOP_K = 3 #Number of retrieved images used to make prediction for a test image.\n",
    "\n",
    "# RANSAC parameters:\n",
    "MAX_INLIER_SCORE = 25\n",
    "MAX_REPROJECTION_ERROR = 7.0\n",
    "# MAX_RANSAC_ITERATIONS = 1000000\n",
    "MAX_RANSAC_ITERATIONS = 10000\n",
    "HOMOGRAPHY_CONFIDENCE = 0.99\n",
    "\n",
    "debug_mode = False\n",
    "\n",
    "if debug_mode:\n",
    "    MAX_NUM_EMBEDDINGS = 10\n",
    "    NUM_PUBLIC_TRAIN_IMAGES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:51.454584Z",
     "iopub.status.busy": "2021-08-28T18:37:51.454009Z",
     "iopub.status.idle": "2021-08-28T18:37:56.001793Z",
     "shell.execute_reply": "2021-08-28T18:37:56.001280Z",
     "shell.execute_reply.started": "2021-08-27T17:32:12.87499Z"
    },
    "papermill": {
     "duration": 4.568354,
     "end_time": "2021-08-28T18:37:56.001909",
     "exception": false,
     "start_time": "2021-08-28T18:37:51.433555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_DIR = '../input/delg-saved-models/local_and_global'\n",
    "DELG_MODEL = tf.saved_model.load(SAVED_MODEL_DIR)\n",
    "DELG_IMAGE_SCALES_TENSOR = tf.convert_to_tensor([0.70710677, 1.0, 2])\n",
    "DELG_SCORE_THRESHOLD_TENSOR = tf.constant(375.)\n",
    "DELG_INPUT_TENSOR_NAMES = [\n",
    "    'input_image:0', 'input_scales:0', 'input_abs_thres:0'\n",
    "]\n",
    "# NUM_EMBEDDING_DIMENSIONS = 1024\n",
    "# NUM_EMBEDDING_DIMENSIONS = 2048\n",
    "# NUM_EMBEDDING_DIMENSIONS = 3072\n",
    "NUM_EMBEDDING_DIMENSIONS = 512\n",
    "\n",
    "\n",
    "GLOBAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(DELG_INPUT_TENSOR_NAMES,\n",
    "                                                ['global_descriptors:0'])\n",
    "\n",
    "LOCAL_FEATURE_NUM_TENSOR = tf.constant(1000)\n",
    "LOCAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(\n",
    "    DELG_INPUT_TENSOR_NAMES + ['input_max_feature_num:0'],\n",
    "    ['boxes:0', 'features:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:56.041747Z",
     "iopub.status.busy": "2021-08-28T18:37:56.041060Z",
     "iopub.status.idle": "2021-08-28T18:37:56.044672Z",
     "shell.execute_reply": "2021-08-28T18:37:56.044211Z",
     "shell.execute_reply.started": "2021-08-27T17:32:17.493959Z"
    },
    "papermill": {
     "duration": 0.026404,
     "end_time": "2021-08-28T18:37:56.044764",
     "exception": false,
     "start_time": "2021-08-28T18:37:56.018360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_hex(image_id) -> str:\n",
    "  return '{0:0{1}x}'.format(image_id, 16)\n",
    "\n",
    "\n",
    "def get_image_path(subset, image_id):\n",
    "  name = to_hex(image_id)\n",
    "  return os.path.join(DATASET_DIR, subset, name[0], name[1], name[2],\n",
    "                      '{}.jpg'.format(name))\n",
    "\n",
    "\n",
    "def load_image_tensor(image_path):\n",
    "  return tf.convert_to_tensor(\n",
    "      np.array(PIL.Image.open(image_path).convert('RGB')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:56.116008Z",
     "iopub.status.busy": "2021-08-28T18:37:56.100399Z",
     "iopub.status.idle": "2021-08-28T18:37:56.129332Z",
     "shell.execute_reply": "2021-08-28T18:37:56.129768Z",
     "shell.execute_reply.started": "2021-08-27T17:32:17.503988Z"
    },
    "papermill": {
     "duration": 0.068938,
     "end_time": "2021-08-28T18:37:56.129904",
     "exception": false,
     "start_time": "2021-08-28T18:37:56.060966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def extract_global_features(filepaths):\n",
    "#     image_paths = [x for x in pathlib.Path(filepaths).rglob('*.jpg')]\n",
    "#     num_images = len(image_paths)\n",
    "#     ids = num_images * [None]\n",
    "#     # Generate an empty matrix where we can store the embeddings of each image\n",
    "#     embeddings = np.empty((num_images, NUM_EMBEDDING_DIMENSIONS))\n",
    "#     for i, image_path in enumerate(image_paths):\n",
    "#         ids[i] = int(image_path.name.split('.')[0], 16)\n",
    "#         image_tensor = read_image(str(image_path), (384, 384)) #384\n",
    "#         prediction1 = MODEL1.predict(image_tensor)\n",
    "#         prediction2 = MODEL2.predict(image_tensor)\n",
    "#         prediction = tf.concat([prediction1, prediction2], 1)\n",
    "# #         prediction = tf.concat([prediction1, prediction2 , prediction1, prediction2], 1)\n",
    "        \n",
    "#         embeddings[i, :] = prediction\n",
    "#     return ids, embeddings\n",
    "\n",
    "def extract_global_features(filepaths):\n",
    "    image_paths = [x for x in pathlib.Path(filepaths).rglob('*.jpg')]\n",
    "    num_images = len(image_paths)\n",
    "    ids = num_images * [None]\n",
    "    # Generate an empty matrix where we can store the embeddings of each image\n",
    "    embeddings = np.empty((num_images, NUM_EMBEDDING_DIMENSIONS))\n",
    "    #print(embeddings.shape)\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        ids[i] = int(image_path.name.split('.')[0], 16)\n",
    "        image_tensor = read_image(str(image_path), (384, 384)) #384\n",
    "        image_tensor_delg = load_image_tensor(image_path)\n",
    "#         features = GLOBAL_FEATURE_EXTRACTION_FN(image_tensor_delg,\n",
    "#                                             DELG_IMAGE_SCALES_TENSOR,\n",
    "#                                             DELG_SCORE_THRESHOLD_TENSOR)\n",
    "#         prediction3 = tf.nn.l2_normalize( tf.reduce_sum(features[0], axis=0, name='sum_pooling'), axis=0, name='final_l2_normalization').numpy().reshape(1, 2048)\n",
    "\n",
    "        prediction1 = MODEL2.predict(image_tensor)\n",
    "#         prediction2 = prediction1#MODEL2.predict(image_tensor)\n",
    "        #print(prediction2.shape)\n",
    "#         prediction = prediction2\n",
    "        #prediction = tf.concat([prediction3 ,prediction1, prediction2 ], 1)\n",
    "        #print(prediction1.shape)\n",
    "        embeddings[i, :] = prediction1\n",
    "    return ids, embeddings\n",
    "\n",
    "\n",
    "def extract_local_features(image_path):\n",
    "  \"\"\"Extracts local features for the given `image_path`.\"\"\"\n",
    "\n",
    "  input_image = load_image_tensor(image_path)\n",
    "  width = tf.cast(tf.shape(input_image)[0], dtype=tf.float32)\n",
    "  height = tf.cast(tf.shape(input_image)[1], dtype=tf.float32)\n",
    "  image_tensor = tf.cast(tf.image.resize(input_image, [tf.cast(pow(2,0.6) * width, dtype=tf.int32), tf.cast(pow(2,0.6) * height, dtype = tf.int32)]), dtype = input_image.dtype)\n",
    "\n",
    "  features = LOCAL_FEATURE_EXTRACTION_FN(image_tensor, DELG_IMAGE_SCALES_TENSOR,\n",
    "                                         DELG_SCORE_THRESHOLD_TENSOR,\n",
    "                                         LOCAL_FEATURE_NUM_TENSOR)\n",
    "\n",
    "  # Shape: (N, 2)\n",
    "  keypoints = tf.divide(\n",
    "      tf.add(\n",
    "          tf.gather(features[0], [0, 1], axis=1),\n",
    "          tf.gather(features[0], [2, 3], axis=1)), 2.0).numpy()\n",
    "\n",
    "  # Shape: (N, 128)\n",
    "  descriptors = tf.nn.l2_normalize(\n",
    "      features[1], axis=1, name='l2_normalization').numpy()\n",
    "\n",
    "  return keypoints, descriptors\n",
    "\n",
    "# def extract_local_features(image_path):\n",
    "#   \"\"\"Extracts local features for the given `image_path`.\"\"\"\n",
    "\n",
    "# #   image_tensor = load_image_tensor(image_path)\n",
    "#   input_image = load_image_tensor(image_path)\n",
    "#   width = tf.cast(tf.shape(input_image)[0], dtype=tf.float32)\n",
    "#   height = tf.cast(tf.shape(input_image)[1], dtype=tf.float32)\n",
    "    \n",
    "#   image_tensor = tf.cast(tf.image.resize(input_image, [tf.cast(pow(2,0.6) * width, dtype=tf.int32), tf.cast(pow(2,0.6) * height, dtype = tf.int32)]), dtype = input_image.dtype)\n",
    "\n",
    "#   features = LOCAL_FEATURE_EXTRACTION_FN(image_tensor, DELG_IMAGE_SCALES_TENSOR,\n",
    "#                                          DELG_SCORE_THRESHOLD_TENSOR,\n",
    "#                                          LOCAL_FEATURE_NUM_TENSOR)\n",
    "\n",
    "#   # Shape: (N, 2)\n",
    "#   keypoints = tf.divide(\n",
    "#       tf.add(\n",
    "#           tf.gather(features[0], [0, 1], axis=1),\n",
    "#           tf.gather(features[0], [2, 3], axis=1)), 2.0).numpy()\n",
    "\n",
    "#   # Shape: (N, 128)\n",
    "#   descriptors = tf.nn.l2_normalize(\n",
    "#       features[1], axis=1, name='l2_normalization').numpy()\n",
    "\n",
    "#   return keypoints, descriptors\n",
    "\n",
    "\n",
    "def get_putative_matching_keypoints(test_keypoints,\n",
    "                                    test_descriptors,\n",
    "                                    train_keypoints,\n",
    "                                    train_descriptors,\n",
    "                                    max_distance=0.75):\n",
    "  \"\"\"Finds matches from `test_descriptors` to KD-tree of `train_descriptors`.\"\"\"\n",
    "\n",
    "  train_descriptor_tree = spatial.cKDTree(train_descriptors)\n",
    "  _, matches = train_descriptor_tree.query(\n",
    "      test_descriptors, distance_upper_bound=max_distance)\n",
    "\n",
    "  test_kp_count = test_keypoints.shape[0]\n",
    "  train_kp_count = train_keypoints.shape[0]\n",
    "\n",
    "  test_matching_keypoints = np.array([\n",
    "      test_keypoints[i,]\n",
    "      for i in range(test_kp_count)\n",
    "      if matches[i] != train_kp_count\n",
    "  ])\n",
    "  train_matching_keypoints = np.array([\n",
    "      train_keypoints[matches[i],]\n",
    "      for i in range(test_kp_count)\n",
    "      if matches[i] != train_kp_count\n",
    "  ])\n",
    "\n",
    "  return test_matching_keypoints, train_matching_keypoints\n",
    "\n",
    "\n",
    "def get_num_inliers(test_keypoints, test_descriptors, train_keypoints,\n",
    "                    train_descriptors):\n",
    "  \"\"\"Returns the number of RANSAC inliers.\"\"\"\n",
    "\n",
    "  test_match_kp, train_match_kp = get_putative_matching_keypoints(\n",
    "      test_keypoints, test_descriptors, train_keypoints, train_descriptors)\n",
    "\n",
    "  if test_match_kp.shape[\n",
    "      0] <= 4:  # Min keypoints supported by `pydegensac.findHomography()`\n",
    "    return 0\n",
    "\n",
    "  try:\n",
    "    _, mask = pydegensac.findHomography(test_match_kp, train_match_kp,\n",
    "                                        MAX_REPROJECTION_ERROR,\n",
    "                                        HOMOGRAPHY_CONFIDENCE,\n",
    "                                        MAX_RANSAC_ITERATIONS)\n",
    "  except np.linalg.LinAlgError:  # When det(H)=0, can't invert matrix.\n",
    "    return 0\n",
    "\n",
    "  return int(copy.deepcopy(mask).astype(np.float32).sum())\n",
    "\n",
    "\n",
    "def get_total_score(num_inliers, global_score):\n",
    "  local_score = min(num_inliers, MAX_INLIER_SCORE) / MAX_INLIER_SCORE\n",
    "  return local_score + global_score\n",
    "\n",
    "\n",
    "def rescore_and_rerank_by_num_inliers(test_image_id,\n",
    "                                      train_ids_labels_and_scores):\n",
    "  \"\"\"Returns rescored and sorted training images by local feature extraction.\"\"\"\n",
    "\n",
    "  test_image_path = get_image_path('test', test_image_id)\n",
    "  test_keypoints, test_descriptors = extract_local_features(test_image_path)\n",
    "\n",
    "  for i in range(len(train_ids_labels_and_scores)):\n",
    "    train_image_id, label, global_score = train_ids_labels_and_scores[i]\n",
    "\n",
    "    train_image_path = get_image_path('train', train_image_id)\n",
    "    train_keypoints, train_descriptors = extract_local_features(\n",
    "        train_image_path)\n",
    "\n",
    "    num_inliers = get_num_inliers(test_keypoints, test_descriptors,\n",
    "                                  train_keypoints, train_descriptors)\n",
    "    total_score = get_total_score(num_inliers, global_score)\n",
    "    train_ids_labels_and_scores[i] = (train_image_id, label, total_score)\n",
    "\n",
    "  train_ids_labels_and_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "  return train_ids_labels_and_scores\n",
    "\n",
    "\n",
    "def load_labelmap():\n",
    "  with open(TRAIN_LABELMAP_PATH, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n",
    "\n",
    "  return labelmap\n",
    "\n",
    "\n",
    "def get_prediction_map(test_ids, train_ids_labels_and_scores):\n",
    "  \"\"\"Makes dict from test ids and ranked training ids, labels, scores.\"\"\"\n",
    "\n",
    "  prediction_map = dict()\n",
    "\n",
    "  for test_index, test_id in enumerate(test_ids):\n",
    "    hex_test_id = to_hex(test_id)\n",
    "\n",
    "    aggregate_scores = {}\n",
    "    for _, label, score in train_ids_labels_and_scores[test_index][:TOP_K]:\n",
    "      if label not in aggregate_scores:\n",
    "        aggregate_scores[label] = 0\n",
    "      aggregate_scores[label] += score\n",
    "\n",
    "    label, score = max(aggregate_scores.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    prediction_map[hex_test_id] = {'score': score, 'class': label}\n",
    "\n",
    "  return prediction_map\n",
    "\n",
    "\n",
    "def get_predictions(labelmap):\n",
    "  \"\"\"Gets predictions using embedding similarity and local feature reranking.\"\"\"\n",
    "\n",
    "  test_ids, test_embeddings = extract_global_features(TEST_IMAGE_DIR)\n",
    "\n",
    "  train_ids, train_embeddings = extract_global_features(TRAIN_IMAGE_DIR)\n",
    "\n",
    "  train_ids_labels_and_scores = [None] * test_embeddings.shape[0]\n",
    "\n",
    "  # Using (slow) for-loop, as distance matrix doesn't fit in memory.\n",
    "  for test_index in range(test_embeddings.shape[0]):\n",
    "    distances = spatial.distance.cdist(\n",
    "        test_embeddings[np.newaxis, test_index, :], train_embeddings,\n",
    "        'cosine')[0]\n",
    "    partition = np.argpartition(distances, NUM_TO_RERANK)[:NUM_TO_RERANK]\n",
    "\n",
    "    nearest = sorted([(train_ids[p], distances[p]) for p in partition],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "    train_ids_labels_and_scores[test_index] = [\n",
    "        (train_id, labelmap[to_hex(train_id)], 1. - cosine_distance)\n",
    "        for train_id, cosine_distance in nearest\n",
    "    ]\n",
    "\n",
    "  del test_embeddings\n",
    "  del train_embeddings\n",
    "  del labelmap\n",
    "  gc.collect()\n",
    "\n",
    "  pre_verification_predictions = get_prediction_map(\n",
    "      test_ids, train_ids_labels_and_scores)\n",
    "\n",
    "#  return None, pre_verification_predictions\n",
    "\n",
    "  for test_index, test_id in enumerate(test_ids):\n",
    "    train_ids_labels_and_scores[test_index] = rescore_and_rerank_by_num_inliers(\n",
    "        test_id, train_ids_labels_and_scores[test_index])\n",
    "\n",
    "  post_verification_predictions = get_prediction_map(\n",
    "      test_ids, train_ids_labels_and_scores)\n",
    "#   print(post_verification_predictions)\n",
    "\n",
    "  return pre_verification_predictions, post_verification_predictions\n",
    "\n",
    "\n",
    "def save_submission_csv(predictions=None):\n",
    "\n",
    "  if predictions is None:\n",
    "    # Dummy submission!\n",
    "    shutil.copyfile(\n",
    "        os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n",
    "    return\n",
    "\n",
    "  with open('submission.csv', 'w') as submission_csv:\n",
    "    csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n",
    "    csv_writer.writeheader()\n",
    "    for image_id, prediction in predictions.items():\n",
    "      label = prediction['class']\n",
    "      score = prediction['score']\n",
    "      csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})\n",
    "\n",
    "\n",
    "def main():\n",
    "  labelmap = load_labelmap()\n",
    "  num_training_images = len(labelmap.keys())\n",
    "  print(f'Found {num_training_images} training images.')\n",
    "\n",
    "  if num_training_images == NUM_PUBLIC_TRAIN_IMAGES:\n",
    "    print('Copying sample submission.')\n",
    "    save_submission_csv()\n",
    "    return\n",
    "\n",
    "  _, post_verification_predictions = get_predictions(labelmap)\n",
    "  save_submission_csv(post_verification_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T18:37:56.164428Z",
     "iopub.status.busy": "2021-08-28T18:37:56.163805Z",
     "iopub.status.idle": "2021-08-28T18:38:02.489393Z",
     "shell.execute_reply": "2021-08-28T18:38:02.489832Z"
    },
    "papermill": {
     "duration": 6.344675,
     "end_time": "2021-08-28T18:38:02.489971",
     "exception": false,
     "start_time": "2021-08-28T18:37:56.145296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1580470 training images.\n",
      "Copying sample submission.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014731,
     "end_time": "2021-08-28T18:38:02.519854",
     "exception": false,
     "start_time": "2021-08-28T18:38:02.505123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 91.462079,
   "end_time": "2021-08-28T18:38:02.741902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-28T18:36:31.279823",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
